{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade accelerate\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --upgrade huggingface_hub\n",
    "!pip install langchain\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain, PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_id = 'stabilityai/stablelm-3b-4e1t'\n",
    "token=\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableLMEpochForCausalLM(\n",
       "  (model): StableLMEpochModel(\n",
       "    (embed_tokens): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (self_attn): Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (o_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=6912, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=6912, bias=False)\n",
       "          (down_proj): Linear(in_features=6912, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  model_id, \n",
    "  trust_remote_code=True,\n",
    "  torch_dtype=\"auto\",\n",
    "  token=token\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_id, \n",
    "  trust_remote_code=True,\n",
    "  torch_dtype=\"auto\",\n",
    "  token=token\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(\n",
    "    pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512, # maximum number of new tokens to be generated\n",
    "        temperature=0.5, # randomness 0.0 to 1.0\n",
    "        do_sample=True, # include current generated text in text generation \n",
    "        trust_remote_code=True, # allows external code from model author to run\n",
    "        device=0,  # Use GPU\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        return_full_text=True,  # langchain expects the full text\n",
    "        repetition_penalty=1.1  # to avoid repitition\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a set of Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m tasks_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mAbout: \u001b[39m\u001b[38;5;132;01m{about}\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mQuestion: Make a list of 5 suitable tasks to \u001b[39m\u001b[38;5;132;01m{teaching_task}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mAnswer: Let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms just list out each item 1 by 1.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m task_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m(\n\u001b[0;32m      8\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[0;32m      9\u001b[0m         template\u001b[38;5;241m=\u001b[39mtasks_template,\n\u001b[0;32m     10\u001b[0m         input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabout\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteaching_task\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m     ),\n\u001b[0;32m     12\u001b[0m     llm\u001b[38;5;241m=\u001b[39mlocal_llm\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "tasks_template = \"\"\"About: {about}\n",
    "\n",
    "Question: Make a list of 5 suitable tasks to {teaching_task}.\n",
    "\n",
    "Answer: Let's just list out each item 1 by 1.\"\"\"\n",
    "\n",
    "task_chain = LLMChain(\n",
    "    prompt = PromptTemplate(\n",
    "        template=tasks_template,\n",
    "        input_variables=[\"name\", \"about\", \"teaching_task\"]\n",
    "    ),\n",
    "    llm=local_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Get up from bed.\n",
      "2. Put on clothes.\n",
      "3. Brush teeth.\n",
      "4. Eat breakfast.\n",
      "5. Go down stairs and take the first step towards the door.\n",
      "6. Go outside and wait for mommy or daddy to open the front door.\n",
      "7. Say bye-bye to doggies.\n",
      "8. Walk with mommy or daddy to the car.\n",
      "9. Sit in the car.\n",
      "10. Drive to school.\n",
      "11. Get out of the car at school.\n",
      "12. Wait for teacher to come to classroom.\n",
      "13. Follow the teacher into classroom.\n",
      "14. Take a seat next to bestest buddy.\n",
      "15. Listen attentively about what is happening today.\n",
      "16. Finish all work quickly so that you can play together.\n",
      "17. Play until it's time to go home.\n",
      "18. Walk back to car, say bye-bye to teacher.\n",
      "19. Walk back to car, say bye-bye to friends.\n",
      "20. Walk back to car, say bye-bye to doggies.\n",
      "21. Sit in the car.\n",
      "22. Drive home.\n",
      "23. Watch TV while waiting for dinner to be prepared.\n",
      "24. Eat dinner.\n",
      "25. Do homework.\n",
      "26. Take shower.\n",
      "27. Sleep.\n"
     ]
    }
   ],
   "source": [
    "generated_tasks = task_chain.run({\n",
    "        \"about\": \"James likes paw patrol.\",\n",
    "        \"teaching_task\": \"teach James how to get ready for school\"\n",
    "})\n",
    "\n",
    "print(generated_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get up from bed. 2. Put on clothes. 3. Brush teeth. 4. Eat breakfast. 5. Go down stairs and take the first step towards the door. 6. Go outside and wait for mommy or daddy to open the front door. 7. Say bye-bye to doggies. 8. Walk with mommy or daddy to the car. 9. Sit in the car. 10. Drive to school. 11. Get out of the car at school. 12. Wait for teacher to come to classroom. 13. Follow the teacher into classroom. 14. Take a seat next to bestest buddy. 15. Listen attentively about what is happening today. 16. Finish all work quickly so that you can play together. 17. Play until it's time to go home. 18. Walk back to car, say bye-bye to teacher. 19. Walk back to car, say bye-bye to friends. 20. Walk back to car, say bye-bye to doggies. 21. Sit in the car. 22. Drive home. 23. Watch TV while waiting for dinner to be prepared. 24. Eat dinner. 25. Do homework. 26. Take shower. 27. Sleep.\n"
     ]
    }
   ],
   "source": [
    "tasks = \"\\n\".join([\" \".join(task.split()[1:]) for task in generated_tasks.strip().split(\"\\n\\n\")[:5]])\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_template = \"\"\"\n",
    "\n",
    "About: {about}\n",
    "\n",
    "Question: What dialogue would be helpful in a game where the task is to \"{task}\"\n",
    "\n",
    "Answer: Let's think step by step\"\"\"\n",
    "\n",
    "dialogue_chain = LLMChain(\n",
    "    prompt = PromptTemplate (\n",
    "        template=dialogue_template, \n",
    "        input_variables=[\"about\",\"task\"]\n",
    "    ),\n",
    "    llm=local_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... I do not see any problem with this, it will be easy to implement since all you need is an object that has 2 properties\n",
      "\n",
      "- name of the character (string)\n",
      "- pronouns (array)\n",
      "\n",
      "    {\n",
      "        name: 'James',\n",
      "        pronouns: ['he'],\n",
      "    }\n",
      "\n",
      "\n",
      "You can find more information about how to use pronouns here https://github.com/kylemathews/puppeteer-extra#using-pronouns\n",
      "\n",
      "The code for adding pronouns to characters looks like this:\n",
      "\n",
      "let pronouns = ['she', 'her', 'hers']\n",
      "const puppeteerExtra = require('puppeteer-extra')\n",
      "const { showErrors } = require('./errorHandler')\n",
      "\n",
      "async function addPronouns(page){\n",
      "  await page.evaluate(() => {\n",
      "    // get all characters on the page and store them into array\n",
      "    const elements = document.querySelectorAll('.characters > div');\n",
      "    Array.prototype.push.apply(elements, Array.from(document.querySelectorAll('.character-details')));\n",
      "    // iterate through each element and set its pronouns property to the pronouns given as argument\n",
      "    for (var i = 0; i < elements.length; i++) {\n",
      "      elements[i].setAttribute(\"data-pronoun\", pronouns[Math.floor((Math.random() * pronouns.length))]);\n",
      "    }\n",
      "  });\n",
      "}\n",
      "\n",
      "addPronouns(page).catch(showErrors);\n",
      "\n",
      "\n",
      "\n",
      ", first you should say something like \"I need\n",
      "to eat.\" After that we can talk about why we want to eat. For example, \"I feel\n",
      "hungry\". Then it will be good to add some details and explain what kind of\n",
      "food we are going to eat. Finally, we can ask for help from someone who knows\n",
      "what food to choose.\n",
      ", shall we? First I'd need some way of knowing\n",
      "if the player has already typed \"t\". Then I could have the program ask if the\n",
      "player wants to type again or quit. If they want to quit then I can tell them\n",
      "to do so and end the program. Otherwise, I could let them know that their input\n",
      "has been accepted and move on.\n",
      "...\n",
      "\n",
      "Firstly, let's make sure that our dialogues are clear and easy for everyone to understand. This will help us avoid any confusion. We can do this by using simple words or sentences.\n",
      "\n",
      "Next, we need to consider how much information should go into each line of dialogue. There are two main types of dialogue - one-way (where only one person speaks) and two-way (when both people speak). For example:\n",
      "\n",
      "  * One-way: 'I want some milk.'\n",
      "\n",
      "  * Two-way: 'Do you have any milk?' *'Yes I have some milk!'\n",
      "\n",
      "It's important not to put too much dialogue on screen at once because it becomes overwhelming. If there are too many lines of text then players may get confused about what they're supposed to be doing next.\n",
      "\n",
      "Finally, remember that if your game has multiple characters then each character needs their own dialogue options so players know who they are talking with!\n",
      "\n",
      "## The Story Behind Paw Patrol Games\n",
      "\n",
      "\"Paw Patrol games are fun!\" That was my first thought when I saw them. After playing them for a while, though, I realized that they were more than just fun; they had great storylines as well.\n",
      "\n",
      "One day, I decided to write down all the different stories I could come up with based on these games. Here are three examples from my list:\n",
      "\n",
      "1. \"The Rescue Team\" - This story involves Chase rescuing Ryder from being trapped under rubble. 2. \"The New Member\" - Marshall joins the team after saving Rocky from drowning in an icy river. 3. \"The Mystery Mission\" - Skye investigates why someone stole Mayor Goodway's car!\n",
      "\n",
      "Each of these stories has its own unique setting and plotline which makes them interesting reads. If you like adventure books then you'll definitely enjoy reading through these Paw Patrol games!\n",
      "\n",
      "## How To Make Your Own Paw Patrol Game?\n",
      "\n",
      "If you love Paw Patrol, then you probably already know how to play the game. But did you know that you can also create your own version of Paw Patrol? It's really easy to do! All you need is some paper, scissors, glue, markers/crayons/pencils, and imagination. Then follow these steps: 1. Draw out the outline of a house on your piece of paper. 2. Cut out the pieces that make up the house. 3. Glue\n",
      ", first we have to find out what this means.\n",
      "\n",
      "What does it mean? This is not clear at all. I can't even guess what it means. So let's go over it again...\n",
      "\n",
      "Let's look for clues that will help us understand what the sentence means.\n",
      "\n",
      "We know that the word \"paw\" comes from the word \"patrol\".\n",
      "\n",
      "So we can assume that the answer has something to do with the words \"paw patrol\".\n",
      "\n",
      "Let's see if there are any other hints on the page.\n",
      "\n",
      "Hmmm... There seems to be an image of a dog and a police car. Maybe this could tell me more about what this puzzle is asking me to do.\n",
      "\n",
      "I'll zoom in on the image so I can get a closer look.\n",
      "\n",
      "Ok, there are two dogs and one police car. The two dogs are chasing each other around the car. That makes sense! But why is it telling me to use the word \"paw\"? Does this puzzle have anything to do with paws or paw prints?\n",
      "\n",
      "Well, let's take a look at the image again.\n",
      "\n",
      "That's right - both dogs have paw prints on their faces. Ok, now I'm getting somewhere. Let's keep going.\n",
      "\n",
      "The next thing I notice is that there is a word written above the picture.\n",
      "\n",
      "It says \"chase\". This doesn't seem very useful though.\n",
      "\n",
      "I wonder if there are any words hidden in the image itself.\n",
      "\n",
      "Maybe I should try to decipher some letters.\n",
      "\n",
      "There are a few different ways you can try to figure out what the letter is. You can change your perspective, rotate the image, zoom in, etc. I tried changing my perspective but nothing seemed to work.\n",
      "\n",
      "Then I noticed that I was looking at the image upside down. When I flipped it upright, suddenly everything came together.\n",
      "\n",
      "As soon as I saw the face of the dog on the left, I recognized the paw print immediately. It looked like the same paw print that was on its face.\n",
      "\n",
      "This must be a clue because when I turned the picture back into a vertical orientation, I realized that the dog on the right had another paw print on his face too.\n",
      "\n",
      "Now that I've figured out what the paw print is, I can figure out what the question wants me to do.\n",
      "\n",
      "If these are paw prints, then the answer must involve using the word \"p\n",
      ", first of all we need an object that can receive input from user and do something with it. So let's use an integer variable for this purpose. Then we need some kind of interface so that our users can interact with it. We can make a simple function which will take as argument an integer value and return boolean result. And lastly we need to define what action is going to happen when user press a button, so we need to write methods for each character. Finally we need to create a main method.\n",
      "\n",
      "Let's start with creating variables. First of all we need to declare the type of our variable because this is required by the IDE (IntelliJ) to know how to interpret data coming from user. This means we have to specify the datatype of our variable. In this case we'll choose int, but we could also choose long or double. It doesn't really matter since int has enough precision for our needs. After declaring the type of our variable we need to give it a name. For example I've named my variable pValue. Now we should assign some initial values to our variable. Here are some examples for you:\n",
      "\n",
      "  1. 1; \n",
      "  2. -3; \n",
      "  3. 0;\n",
      "  4. 10; \n",
      "  5. 20;\n",
      "\n",
      "In this simple program we just want to print out the current value of our variable, but if we want to do more interesting things than simply printing out our variable then we need to add some logic. Our next step is to implement the logic for our variable. The easiest way to do this is to write methods for each character. For example we can make a getPaw() method which will return the current value of our variable. If we want to change the value of our variable we can call setPaw(int newValue). If we don't want any changes to occur at all then we can call reset(). These three methods represent basic actions that can be done on our variable. But we haven't yet defined the behaviour of our variable. We still need to decide what happens when user presses a key. To achieve this we need to define two different types of events. One event represents pressing a key while another one represents releasing a key. Pressing a key leads to changing the value of our variable and releasing a key does nothing. As you can see there is no difference between these two events. However they are important for us because without them we won't be able to handle user interaction. There are two\n",
      ". First, what are the options for saying this?\n",
      "\n",
      "James says \" \"\n",
      "\n",
      "- That doesn't make sense\n",
      "\n",
      "\" \"\n",
      "\n",
      "- I don't know how to say that\n",
      "\n",
      "\" \"\n",
      "\n",
      "- It sounds like you're making it up as you go along\n",
      "\n",
      "That leaves us with three options.\n",
      "\n",
      "So now we have some ideas about what might happen if we try each of those and then we can think about why they might work or not.\n",
      "\n",
      "The first option is that he just says \" \". This could go either way - it could mean that he thinks his friend is stupid because he doesn't speak English (the game could ask him why he thought this) or it could mean that he wants to get away from the conversation because he finds it boring.\n",
      "\n",
      "If we want the second option, which is that he says \" \", we need to make sure that we prompt him enough so that he has time to think of an answer. We could do this by asking questions like \"What does 'paw patrol' sound like?\" or \"Can you say 'paw patrol'?\" Or we could give him some clues (\"I'm thinking of something that has four legs and a strong voice\") and see whether he understands them.\n",
      "\n",
      "Finally, if we want him to say \" \", we'll need to add some more context to the sentence before he answers. For example, maybe we could say \"You don't understand me\". If he still doesn't respond, we could prompt him with \"Do you understand me?\"\n",
      "\n",
      "We also need to keep track of all these different possibilities so that we know when we've tried everything out. At some point, we'll probably run out of things to say!\n",
      "\n",
      "Let's try one more thing...\n",
      "\n",
      "Now let's try another possible scenario.\n",
      "\n",
      "Scenario 2: The player asks James what he said.\n",
      "\n",
      "Options:\n",
      "\n",
      "  * James replies \" \"\n",
      "  * James replies \" \"\n",
      "  * James replies \" \"\n",
      "  * James replies \" \"\n",
      "  * James replies \" \"\n",
      "\n",
      "Why might this work?\n",
      "\n",
      "Well, it depends on the question. If the question is \"Did you say anything?\", then James will know that the other person isn't interested in what he had to say. On the other hand, if the question is \"Did you say \"paw patrol\"?\" then James won't know whether he should reply \"yes\" or \"no\", because there's no clear answer\n",
      ":\n",
      "\n",
      "1) When you enter the room, you see that there are some boxes and a dog.\n",
      "\n",
      "2) You want to go with your box into the other room.\n",
      "\n",
      "3) But first you need to decide on how many steps it will take to get there.\n",
      "\n",
      "4) And then you can start walking.\n",
      "\n",
      "5) If you don't finish the walk, the game ends and you have to try again.\n",
      "\n",
      "  * The next question is what should happen when you click on the dog?\n",
      "  * Well, I think it should say something like \"You are not allowed to do that.\"\n",
      "  * Or if you are allowed, maybe it says \"I'm happy because of this\".\n",
      "\n",
      "In this case, the player doesn't really understand why he has to move forward. He just does it. It would be better if he understood why he needs to do so. So let's ask him another question:\n",
      "\n",
      "What would be an understandable explanation for the fact that you need to move forward?\n",
      "\n",
      "Answer: Well, we could say something like this:\n",
      "\n",
      "\"The reason why you need to move forward is because otherwise the game won't end correctly. So please keep going.\"\n",
      "\n",
      "So now you know what the user wants from the program. Now you have to write down all the things that you think you can give them. For example, you can tell them about the game or you can show them the game. This way they'll find out more about the game.\n",
      "\n",
      "When you're done writing everything down, you can put these ideas together as one big story. Then you can start thinking about how to make the user experience fun.\n",
      "\n",
      "Let's say you're making a game called \"Farm Life\". Your main goal is to help the farmer raise his animals and crops. In order to achieve this, you need to plant seeds, water plants and feed animals.\n",
      "\n",
      "Now imagine yourself sitting at your computer, looking at the screen. On top of the screen is a picture of a farm with different types of trees, grasses and flowers. Below the image are four buttons. One button says \"Start\", two buttons say \"Plant\", and the last button says \"Water\".\n",
      "\n",
      "If you press the \"Start\" button, the first thing you'll notice is that the background changes color. Maybe it turns green or blue. Next, you see another picture of a field with seeds scattered around. Underneath the seed picture is\n",
      " what we want to do, and how to do it.\n",
      "\n",
      "Question: Why did you choose that name?\n",
      "\n",
      "Answer: It was easy to remember.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". First, you need to know what the dog says when he sees his friends. Second, you need to know how to pronounce it. Third, you have to find some way of using that phrase in your game. Fourth, you need to make sure that any other words or phrases used are pronounced in such a way as not to confuse the player. And fifth, if there are multiple possible ways of pronouncing something (i.e., with an accent mark), then you need to decide which one will work best for your audience and use that.\n",
      "\n",
      "Finally, remember that while this may seem like a lot of work up front, it will save you time later on down the road because once you've created a character that can speak English, you'll also be able to create characters who can speak French, Spanish, Japanese, Chinese, etc.\n",
      "\n",
      "And if you're looking for a fun way to teach kids about language learning outside of school - check out our new app!\n",
      "\n",
      "#  Chapter 3\n",
      "\n",
      "## The Science Behind Wordplay\n",
      "\n",
      "In this chapter we explore the science behind wordplay. We look at why games are so important for children's development and how they can help them learn more effectively. Finally, we discuss why it's important for parents to play games with their kids and provide some tips on how to get started.\n",
      "\n",
      "What Is Wordplay?\n",
      "\n",
      "Wordplay refers to the use of words in a creative way to achieve a specific goal. It can include puns, rhymes, riddles, tongue twisters, jokes, and many others. In this article, we focus specifically on wordplay in educational settings.\n",
      "\n",
      "Why Do Games Matter?\n",
      "\n",
      "Games matter because they allow us to experience real-world situations without actually having to deal with them. This means that we don't have to worry about making mistakes, getting hurt, or being embarrassed because everything happens inside our heads instead of in reality. For example, playing Monopoly might give you insight into what it feels like to own property but not necessarily anything else related to business management skills or financial planning. The same goes for board games such as Risk or Battleship : although these games involve strategy and tactics, they do not require knowledge of military history or naval warfare theory. However, understanding these concepts through play does prepare players for future challenges in life that require similar decision-making processes.\n",
      "\n",
      "How Does Game Play Help Children Learn More Effectively?\n",
      "\n",
      "Game play helps children learn more effectively by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", here are some ideas that may help you write\n",
      "dialogue for this task:\n",
      "\n",
      "-James says he loves Paw Patrol;\n",
      "\n",
      "-Paw Patrol is great!\n",
      "\n",
      "-Let me show you my favourite episode;\n",
      "\n",
      "-I love it when Skye saves Ryder and Rocky.\n",
      "\n",
      "# Chapter 2.5 - Game Dialogue Examples [2]\n",
      "\n",
      "About: If you have ever played Mario Kart on Nintendo 64 or Wii then you will\n",
      "know what we mean about asking people if they want to play a game against each\n",
      "other.\n",
      "\n",
      "Question: Would you like to race?\n",
      "\n",
      "Answer: Yes please! Let me put on my helmet.\n",
      "\n",
      "About: This example shows how to ask someone to do something which can also be\n",
      "used as dialogue in games. We use the same words but with different intonation\n",
      "to make them sound more natural. You could add a question mark after this line\n",
      "and use it as your own dialogue for your game.\n",
      "\n",
      "Question: Do you want to go swimming now?\n",
      "\n",
      "Answer: I don't know yet, let me check my diary first.\n",
      "\n",
      "About: Here is an example of using the word 'yet' to talk about future events\n",
      "in a neutral way.\n",
      "\n",
      "Question: Have you seen the new movie yet?\n",
      "\n",
      "Answer: No, not yet. When did it come out?\n",
      "\n",
      "About: In this sentence we are talking about past events.\n",
      "\n",
      "Question: Did you see the film last night?\n",
      "\n",
      "Answer: Yes, I went to see it at the cinema. It was amazing!\n",
      "\n",
      "About: The next example uses the word 'actually'.\n",
      "\n",
      "Question: How long has it been since we met?\n",
      "\n",
      "Answer: Actually, it feels like only yesterday.\n",
      "\n",
      "About: This one is similar to the previous one except we are talking about\n",
      "something that happened recently.\n",
      "\n",
      "Question: How long has it been since we saw each other?\n",
      "\n",
      "Answer: Not very long actually. Only two weeks ago!\n",
      "\n",
      "About: Another example using the word 'actually', this time used to express\n",
      "surprise.\n",
      "\n",
      "Question: Wait, why haven't you told me before?\n",
      "\n",
      "Answer: Actually, I didn't realise until today.\n",
      "\n",
      "About: Here is an example of using the word 'actually' to talk about recent\n",
      "events.\n",
      "\n",
      "Question: Have you heard about the party tonight?\n",
      "\n",
      "Answer: Actually,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about what we want to say. First, it's important that our players know who we are talking to and how they can contact us. So the first thing I'd like to say is \"Hello\" or \"Hi.\" If we're at home, then I might say \"Hey [player name], I'm James\". But if this was on a train or something else public, I would probably just use their first name instead of calling them by their full name. After that, I might ask them how they are doing today. This could be done with an emoji or a short sentence. Then, depending on how much time we have left, we could talk about other things such as what's going on in our lives currently, anything exciting happening recently, or even some jokes! We could also share something personal that only two people will understand between ourselves but not anyone else listening nearby - for example, if one player has been feeling sick lately while another hasn't noticed any symptoms yet because they haven't taken care of themselves properly (eating well etc.), then maybe telling each other this information would help both parties feel better when interacting together again later down the line due to knowing more about their own health statuses compared with others around them.\n",
      "\n",
      "What do you mean?\n",
      "\n",
      "I've read the rules and tried to follow them, but my game still isn't working. It seems like there's no way out of this mess.\n",
      "\n",
      "If you're having trouble understanding what the rules are, or you're confused about why your game isn't working, don't worry! There are plenty of ways to get help from other players. You can always check out the comments section below each post in order to see what other people are saying about their games too; sometimes these tips can give you ideas about how best approach solving problems like these ones yourself. Or if none exist yet (which sadly happens quite often), try posting over here asking someone specific questions related specifically towards your issue so that they may respond appropriately accordingly!\n",
      "\n",
      "The following tips should hopefully make things easier than before...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Step 1: I like paws.\n",
      "\n",
      "Step 2: I love paws.\n",
      "\n",
      "Step 3: I need paws.\n",
      "\n",
      "Step 4: B is for bunny, the letter that begins my name.\n",
      "\n",
      "Step 5: Therefore, I want a bunny named Paw.\n",
      "\n",
      "Step 6: I can't have a bunny because it's not allowed.\n",
      "\n",
      "Step 7: I should make up an excuse about how I need a rabbit and then get one later.\n",
      "\n",
      "Step 8: I don't know what to say when she asks me why I need it.\n",
      "\n",
      "Step 9: I'll tell her it's for a project at school.\n",
      "\n",
      "Step 10: She will probably ask me what kind of project.\n",
      "\n",
      "Step 11: I'll tell her I'm making a book about rabbits.\n",
      "\n",
      "Step 12: Then she might ask me if there are any animals in the book besides the rabbit.\n",
      "\n",
      "Step 13: I'll answer honestly and say no.\n",
      "\n",
      "Step 14: If she asks why, I'll tell her it has something to do with my dog.\n",
      "\n",
      "Step 15: I could say I have a great idea for a story about a dog who wants to go on adventures but needs help from his friends.\n",
      "\n",
      "Step 16: This is good, but now we're getting into a lot of details.\n",
      "\n",
      "Step 17: I could just say, \"I've always wanted a pet.\"\n",
      "\n",
      "Step 18: But this doesn't sound very convincing.\n",
      "\n",
      "Step 19: Maybe I should just say that I want a rabbit so that I can write about it?\n",
      "\n",
      "Step 20: That's even worse!\n",
      "\n",
      "Step 21: How about I say I haven't had a pet since I was little and I miss having a pet.\n",
      "\n",
      "Step 22: Well...maybe that sounds better than saying I want a rabbit.\n",
      "\n",
      "Step 23: It still sounds weird though.\n",
      "\n",
      "Step 24: Okay, well maybe I should just say I want a pet.\n",
      "\n",
      "Step 25: Maybe it's time to stop thinking about this problem.\n",
      "\n",
      "Step 26: I guess I'll wait until tomorrow and see what happens.\n",
      "\n",
      "Step 27: I wonder if I'll get in trouble for lying?\n",
      "\n",
      "Chapter Twenty-Eight - The Lie About the Pet\n",
      "\n",
      "James woke up the next morning and looked around. He hadn't been able to sleep. His mind kept going back over the conversation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "1)  What does he say?\n",
      "\n",
      "2)  How do we know that he says it?\n",
      "\n",
      "3)  Why are we interested in this information?\n",
      "\n",
      "4)  Is there any other way of getting this information?\n",
      "\n",
      "5)  If yes, how could you get it?\n",
      "\n",
      "6)  Which one comes first?\n",
      "\n",
      "7)  Is the answer true or false?\n",
      "\n",
      "8)  What new questions arise out of this dialogue?\n",
      "\n",
      "9)  Are there any missing pieces in my understanding?\n",
      "\n",
      "10)  What else can I ask?\n",
      "\n",
      "11)  What more do I need to understand the meaning of his words?\n",
      "\n",
      "12)  Can I use this as an example for future games?\n",
      "\n",
      "13)  Is it possible to make assumptions about what he means without asking him directly?\n",
      "\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n",
      "    *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", and I'll try to help you with these questions.\n",
      "\n",
      "1) First of all, we must understand what this word means, so let's look at it first.\n",
      "\n",
      "2) After that, we can move on to the next question.\n",
      "\n",
      "3) The last thing we need to do is connect everything together.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about what a player should do, and then we will write down some text that can help him out.\n",
      "\n",
      "- \"I want to ____\" - \"How to ____?\" - \"Here are some examples of how to ____.\" - \"When I _____, this happens.\"\n",
      "\n",
      "There is no need for any other text, because if the player really wants something, he/she will find it on his own, or ask someone else who knows.\n",
      "\n",
      "## About making games for kids\n",
      "\n",
      "Let's imagine that you have decided to create a board game with your friends. You have collected all the necessary equipment and now you're ready to start playing. How would you describe the rules?\n",
      "\n",
      "The following description of the game is not very sophisticated, but at least you understand what the players' goal is.\n",
      "\n",
      "  1. Goal of the game: The first one to get rid of all their pieces wins.\n",
      "\n",
      "  2. Rules: Take turns moving your piece forward along the path, and when there is an obstacle in your way, move back until you go around it. If you land on another player's piece, take her piece away from the board. The winner is the last person left standing.\n",
      "\n",
      "That's it! Your game is done! Now let's play it!\n",
      "\n",
      "This simple example shows us two things:\n",
      "\n",
      "  * A game doesn't require too much explanation to begin with;\n",
      "\n",
      "  * When you explain the rules of the game, you don't need to tell everything. It's enough just to say what needs to be done.\n",
      "\n",
      "So, the next time you make a game for kids, try to follow these guidelines:\n",
      "\n",
      "  * Make sure that the game is clear and easy to learn;\n",
      "\n",
      "  * Don't add unnecessary details to the instructions. Just give them the information they need.\n",
      "\n",
      "## About making games for adults\n",
      "\n",
      "You know that there are certain rules for creating games for children, but what about making games for adults? Are there any special requirements?\n",
      "\n",
      "In fact, there aren't so many differences between making a game for adults and making a game for kids. But there is still one important difference.\n",
      "\n",
      "Adults know more than children, so they don't need as much guidance while playing a game. For example, they already know that if they want to win, they must beat the computer. They also know that they shouldn't cheat. So, they can easily figure out what to do during the game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about what this means. First, we know that the sentence has two clauses separated by a comma. The first clause contains an action verb (\"jump\") and its object (\"on the bed\"). The second clause also contains an action verb (\"like\") but it does not have any objects. So the question is: Which of these two clauses do you want your character to say?\n",
      "\n",
      "Let's take a look at another example from a different game:\n",
      "\n",
      "I'm going to make some tea. (action)\n",
      "\n",
      "I like drinking tea! (belief)\n",
      "\n",
      "In this case, I am pretty sure that the player wants me to say something about my belief, so I will probably need to use a speech bubble. But before I can decide whether or not to use a speech bubble, I should ask myself which statement is more important for the context of the story. In both cases, the statements are equally relevant to the situation, so there is no clear answer as to who should speak next. However, if one of them were less important than the other, then I could choose between using a speech bubble on either statement. For instance, if I wanted to emphasize how much I enjoy making tea over how much I love drinking it afterwards, then I might use a speech bubble only around the part about making tea since that's the most important thing happening right now.\n",
      "\n",
      "So let's try again with our original example:\n",
      "\n",
      "James likes paws patrol.\n",
      "\n",
      "What dialogue would be helpful in a game where the task is to \" \"\n",
      "\n",
      "Now we know that the player wants us to talk about his/her feelings towards the subject matter of the game. That means we'll need to include some kind of emotional response in order to convey this information effectively. It doesn't necessarily mean that he/she needs to express their thoughts aloud; after all, sometimes people feel things without saying anything at all. Instead, we can show how someone feels through facial expressions, body language, or even music (if appropriate). We might also consider including some background noise like wind chimes or crickets chirping nearby - just enough so that they don't distract too much from the conversation itself while still adding some extra atmosphere. This approach works well when creating games set outdoors because nature provides plenty of opportunities for natural sounds such as birds singing or leaves rustling in the breeze.\n",
      "\n",
      "On the other hand, if we're designing a game based solely indoors then perhaps we'd want to add some sort of sound effect instead - maybe something like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Step 1: We need a number that means two. 2, 4, 6, 8, 10 are all numbers that mean two. But we don't want those because they aren't words. So how about 3? It also means three but it doesn't have any other meaning like 2 does.\n",
      "\n",
      "Step 2: Now let's ask what sounds do these make. 2 makes the sound of two people talking at once. Does this help us figure out what this word means? No. You can say \"two\" and you know what it means. But if you wanted to, you could use the phrase \"the sound of two people talking at once\". This phrase helps us understand what the number 2 means. The same goes for 3. If you said \"three\", then you'd get some idea of what the number meant. That's why we haven't used numbers except as letters. They're not words.\n",
      "\n",
      "Step 3: We've decided that the best way to tell someone \"two\" is to say \"two\" or \"the sound of two people talking at once.\" But how do we get someone else to understand what you're saying? We should write it down! Numbers written on paper are much easier to read than numbers spoken aloud.\n",
      "\n",
      "So now that we know \"2\" means two, we just need to show someone. And since we've been using letters, we'll use them again. Here is a picture of a piece of paper with a letter \"2\" on it. When you see this, you probably already knew what it meant. But let's pretend that I had never heard the word before. Then when I saw the letter \"2\" I would know it meant two. When I told another person what I was reading, they would know too.\n",
      "\n",
      "Now that we have this concept figured out, let's look at a real example of a game where we need to \"2\". In my last book, I wrote about something called Pictionary (it's an app on your phone). As you may remember, one player has a character on their screen who must draw whatever the other players give them. To help them, each player chooses a colour and writes that colour on their hand. For example, if red was chosen, the player would put their left hand up and say \"red\" so everyone knows which hand to point to if they want the colour red. Then when the player drew, everyone would know what color the drawing was supposed to be.\n",
      "\n",
      "Well\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and find out what we can do...\n",
      "\n",
      "1) \"I like paws.\"\n",
      "\n",
      "2) \"You like paws?\"\n",
      "\n",
      "3) \"Yes, I like paws.\"\n",
      "\n",
      "4) \"Why do you like paws?\"\n",
      "\n",
      "5) \"Because they are soft!\"\n",
      "\n",
      "6) \"They are soft because...\"\n",
      "\n",
      "7) \"Paws are made of fur and skin.\"\n",
      "\n",
      "8) \"What kind of skin?\"\n",
      "\n",
      "9) \"Skin from cows.\"\n",
      "\n",
      "10) \"Cows have skin?\"\n",
      "\n",
      "11) \"Yes, cows have skin just like humans.\"\n",
      "\n",
      "12) \"So, cows have skin too? And paws?\"\n",
      "\n",
      "13) \"Yes, cows have paws too. They look like this.\"\n",
      "\n",
      "14) \"And cows also have ears and eyes like us?\"\n",
      "\n",
      "15) \"Yes, but they don't have noses or mouths.\"\n",
      "\n",
      "16) \"Then how do they breathe?\"\n",
      "\n",
      "17) \"Through their skin.\"\n",
      "\n",
      "18) \"Wow! That's amazing! But why did God create such an animal as a cow?\"\n",
      "\n",
      "19) \"God created all animals for different purposes so that there could be no\n",
      "lack in human life.\"\n",
      "\n",
      "20) \"He wanted to make sure that people had everything they needed to survive.\"\n",
      "\n",
      "21) \"And He gave them the ability to produce milk through which babies were fed\n",
      "and butter was produced that became food and fuel.\"\n",
      "\n",
      "22) \"It wasn't only cows who benefited from milk production. Other species\n",
      "also benefited from it.\"\n",
      "\n",
      "23) \"For example, horses and camels drink milk.\"\n",
      "\n",
      "24) \"But not all mammals benefit directly from milk. Many other species also\n",
      "benefit indirectly from milk.\"\n",
      "\n",
      "25) \"Like bears, elephants, rhinos, monkeys, gorillas, leopards, tigers, and\n",
      "many more.\"\n",
      "\n",
      "26) \"Even some birds drink milk.\"\n",
      "\n",
      "27) \"That's unbelievable! Have you ever seen a bird drinking milk?\"\n",
      "\n",
      "28) \"No, but I heard about it.\"\n",
      "\n",
      "29) \"Did you hear it from your parents?\"\n",
      "\n",
      "30) \"Yes, my father told me that he saw a bird drinking milk once at night when\n",
      "he went outside with his flashlight.\"\n",
      "\n",
      "31) \"Really? When did he see it?\"\n",
      "\n",
      "32) \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " how we can make this work? First, let's see what the user sees when he clicks on the button.\n",
      "\n",
      "The answer will be something like this:\n",
      "\n",
      "  * When you click on the button, the message appears with the text of the question.\n",
      "  * The game also displays a list of answers for you to select from.\n",
      "\n",
      "To begin with, it makes sense to add an image that tells us that there are several options and we have to choose one of them. After all, if the user does not know which option to pick, they won't understand the point of the exercise.\n",
      "\n",
      "So here is the code for the next part.\n",
      "\n",
      "    <div class=\"options\">\n",
      "        {% for item in items %}\n",
      "            <img src=\"{{ url_for('static', filename='images/option-{{item}}') }}\" alt=\"\">\n",
      "        {% endfor %}\n",
      "    </div>\n",
      "\n",
      "Now let's look at the code for displaying the question itself.\n",
      "\n",
      "    <p>{{ question }}</p>\n",
      "\n",
      "In order to display the selected answer, we need to use the <select> element. This element allows you to specify any number of options. We want to add an option for each item in our list. To do this, we need to create a variable called 'items' and initialize it with our list. In addition, we need to include the variable in the context so that we can access it later.\n",
      "\n",
      "Next, we need to create an array that will contain the name of each option. For example, ['option1','option2','option3']. Then we loop through the array and create an option element with its own attribute. Finally, we need to assign a value to each option using the index variable. So now we should have something like this:\n",
      "\n",
      "    {% for item in items %}\n",
      "        <option value=\"{{item}}\">{{item}}</option>\n",
      "    {% endfor %}\n",
      "\n",
      "Finally, we just need to connect everything together so that the user selects an option and then presses the submit button. Here is the final result:\n",
      "\n",
      "    <form action=\"/answers\" method=\"post\">\n",
      "      <div class=\"options\">\n",
      "        {% for item in items %}\n",
      "          <img src=\"{{ url_for('static', filename='images/option-{{item}}') }}\" alt=\"\">\n",
      "        {% endfor %}\n",
      "      </div>\n",
      "      <input type=\"submit\" id=\"answer\" />\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\n",
      "Step 1: The player wants to \"paw\".\n",
      "\n",
      "Step 2: How can we help?\n",
      "\n",
      "Step 3: We could say, \"Go ahead and p!\"\n",
      "\n",
      "Step 4: But that sounds like a command, not an invitation.\n",
      "\n",
      "Step 5: Hmm... maybe instead of saying \"go ahead and p\", we could just say \"p\"\n",
      "\n",
      "Step 6: And then they will know what to do.\n",
      "\n",
      "Step 7: So instead of saying \"go ahead and p\" - let's just say \"p\".\n",
      "\n",
      "Step 8: Then it won't sound like a command but rather an instruction.\n",
      "\n",
      "Step 9: A good instruction for players to follow along with.\n",
      "\n",
      "This was my process when creating the dialogue below. I hope this helps you create your own instructions.\n",
      "\n",
      "##  Instructions (Dialogue)\n",
      "\n",
      "### About: James likes paw patrol.\n",
      "\n",
      "Question: What dialogue would be helpful in a game where the task is to \"P\"\n",
      "\n",
      "Answer: Go ahead and p!\n",
      "\n",
      "# Chapter 10\n",
      "\n",
      "##  Avoiding Dialogue That Sounds Like Commands\n",
      "\n",
      "When making dialogue, try to avoid dialogue that sounds like commands.\n",
      "\n",
      "For example, these two lines are both telling the player to click on something.\n",
      "\n",
      "> Click here.\n",
      ">\n",
      "> Click on the green flag.\n",
      "\n",
      "But one of them feels more natural than the other. Which one does? It depends on context. In a game about clicking things, it seems more natural to tell the player to \"click on the green flag.\" However, in games about puzzles or adventure games, it might feel more natural to have the player click on something else first before being told to click on the green flag.\n",
      "\n",
      "When deciding which way to go, consider how similar the tasks are. If the two tasks are very different, then it makes sense to use the same wording for both of them.\n",
      "\n",
      "However, if the tasks are very similar, then using different wording makes more sense. For example, if there were two doors in a room, and one door leads to a secret passageway and the other door leads to a dead end, it doesn't make much sense to tell the player to \"open the door\" since opening either door is essentially the same thing. Instead, it makes more sense to give them two separate instructions.\n",
      "\n",
      "So remember, don't use the exact same words for all the actions in your\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about what could be done here...\n",
      "\n",
      "- The user starts with an empty string and has to type something into it.\n",
      "\n",
      "- A prompt appears on the screen, which could contain words like 'type','say' or 'write'.\n",
      "\n",
      "- They have to enter something, which will then replace the original string.\n",
      "\n",
      "- The string isn't just replaced by whatever they typed, but also gets extended with some kind of word boundary character (e.g.'') that indicates when they're finished typing.\n",
      "\n",
      "- If the input doesn't match any patterns or if the end of the line is reached, the program should display a help message and wait for another input.\n",
      "\n",
      "- If everything went well so far, the new string should get printed out on the screen.\n",
      "\n",
      "As you can see, this sounds quite straightforward, but there are still some things we need to consider before implementing anything. For example, how do we handle punctuation? Should we allow them or not? How do we deal with special characters? Do we want to support multi-line inputs? And so forth.\n",
      "\n",
      "The first thing I'd recommend doing is writing down all these questions and coming up with answers for them one by one. Once you've got your list of requirements nailed down, you can start looking at existing tools that might already solve your problem (or parts of it). There are many text editors available for Python, such as PyCharm, Sublime Text, Atom, Komodo Edit, Vim, Emacs, Notepad++, etc.. We'll go through each of them and look at their features in more detail later. But for now let's focus on our main goal - making sure that we know exactly what we want our final product to look like!\n",
      "\n",
      "## 2.2.1. Text Editors\n",
      "\n",
      "With the question about text editors solved, let's take a closer look at some of the most popular ones.\n",
      "\n",
      "### 2.2.1.1. Vim\n",
      "\n",
      "Vim is a powerful editor designed primarily for programmers. It has been around since the early 1990s and is still actively developed today. It offers an extensive set of features including syntax highlighting, indentation management, file navigation and many others.\n",
      "\n",
      "One interesting feature of Vim is its plugin system. This allows users to add custom functionality to the editor without having to modify the core codebase itself. Plugins can range from simple snippets of code that provide additional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", what we have here: We need to t something.\n",
      "\n",
      "What should it be? The answer is obvious! It must be a dog. So let's ask the question again: What should I say when I want to \"t\" a dog?\n",
      "\n",
      "Well... maybe you could use some words like \"get\", \"go\", or \"come\". But this isn't enough - these are not words that any normal person will understand. There has got to be more. Maybe there are other words for dogs which are also used as verbs.\n",
      "\n",
      "The best way to know if a word can be used as a verb is to look at the context of its meaning. In English, we often refer to something happening inside our body with verbs such as \"to breathe\", \"to eat\", and so on. If a word means something similar but is used to describe an object instead, then we can assume it works just as well as a verb. For example, \"I'm hungry.\" This sentence clearly refers to feelings within us rather than physical actions outside of ourselves. When people talk about being tired, they don't mean that their bodies are exhausted; they're referring to how they feel emotionally. Similarly, when someone says \"he was sad,\" they aren't talking about his moods; they're describing how he felt emotionally during certain incidents throughout life (notably those involving death).\n",
      "\n",
      "So now let's go back to our original problem: How do we describe what happens between us and a dog? Well, first off all, we already knew that \"t\" meant touch, so we'd better keep using that term because it makes sense. Next up: \"touch\" usually describes something physical, right? So let's see what else we've learned about touching things: When someone touches another person's hand, they may say \"greeting\" instead of simply calling out \"hello\"; likewise, when two friends hug each other for comfort after getting into a fight, one might say \"hugging\" while the other uses \"holding hands.\" Finally, sometimes people call themselves \"close\" without even touching anyone else physically. All of these examples show that \"touching\" can take place in many different ways, depending upon context. Now that we know how much variety exists amongst various types of contact, let's try asking another question: What does it mean when someone calls himself/herself \"close\"?\n",
      "\n",
      "When asked what it means when someone calls him- or herself close, James replies: \"It\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". First, we need a question that asks for an answer. We can ask what colour they like. Second, we have to give them some options so that they don't get stuck with no choice at all. One option might be 'pink' or 'blue'. Thirdly, we want to make sure that when the player gives us their answer, it actually means something in our game. So let's add a bit of logic here - if they say pink then we'll turn the screen red and tell them that they're wrong! And if they say blue then we'll turn the screen green and tell them that they're right! Finally, we also want to make sure that there are only two answers possible. If this wasn't true then you could just keep on guessing until one of them worked out correctly which obviously wouldn't be very fun...\n",
      "\n",
      "# Chapter 16: Getting Started\n",
      "\n",
      "When I was first learning programming as a kid, I remember being really confused about how to start my games. There were lots of different languages (or rather, sets of rules) to learn and each seemed quite complicated and scary. But eventually, after many hours of trial and error, I found a way into making games that suited me best. It involved using blocks instead of code. Blocks are just little pieces of instructions that you can drag onto your computer screen and arrange however you like. You use these blocks to create programs called Scratch Projects.\n",
      "\n",
      "There are loads of other ways to get started too but Scratch is probably the easiest and quickest way to try your hand at coding. Once you've made a few projects you'll soon find yourself thinking about things like if statements and loops and variables. In fact, once you've done a few projects you'll probably wonder why you didn't discover scratch sooner!\n",
      "\n",
      "Scratch has a whole range of tutorials and help pages, including ones specifically designed for kids. The website [http://scratch.mit.edu] is easy to navigate and there's plenty of information available. After watching a tutorial video or two, you should feel ready to jump straight into making your own games.\n",
      "\n",
      "If you'd like to know more about Scratch, check out this book. It explains everything you need to know before getting started.\n",
      "\n",
      "# Chapter 17: Game Design\n",
      "\n",
      "The most important thing you will ever do as a game designer is design your game. This includes deciding what kind of game it's going to be, who your audience is,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alanj\\OneDrive - Technological University Dublin\\Year 4\\4th Year Project\\stablelm-3b.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alanj/OneDrive%20-%20Technological%20University%20Dublin/Year%204/4th%20Year%20Project/stablelm-3b.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m tasks:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alanj/OneDrive%20-%20Technological%20University%20Dublin/Year%204/4th%20Year%20Project/stablelm-3b.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(dialogue_chain\u001b[39m.\u001b[39;49mrun({\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alanj/OneDrive%20-%20Technological%20University%20Dublin/Year%204/4th%20Year%20Project/stablelm-3b.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mabout\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mJames likes paw patrol.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alanj/OneDrive%20-%20Technological%20University%20Dublin/Year%204/4th%20Year%20Project/stablelm-3b.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtask\u001b[39;49m\u001b[39m\"\u001b[39;49m : task\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alanj/OneDrive%20-%20Technological%20University%20Dublin/Year%204/4th%20Year%20Project/stablelm-3b.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     }))\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    504\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\llm.py:108\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    105\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 108\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\llm.py:120\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    118\u001b[0m callbacks \u001b[39m=\u001b[39m run_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m    121\u001b[0m         prompts,\n\u001b[0;32m    122\u001b[0m         stop,\n\u001b[0;32m    123\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    124\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mbind(stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs)\u001b[39m.\u001b[39mbatch(\n\u001b[0;32m    128\u001b[0m         cast(List, prompts), {\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[0;32m    129\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\base.py:507\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    500\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    501\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    505\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    506\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 507\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\base.py:656\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    642\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    643\u001b[0m         )\n\u001b[0;32m    644\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    646\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         )\n\u001b[0;32m    655\u001b[0m     ]\n\u001b[1;32m--> 656\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[0;32m    657\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    658\u001b[0m     )\n\u001b[0;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    660\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\base.py:544\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[0;32m    543\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 544\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    545\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    546\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\base.py:531\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    523\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    528\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    529\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 531\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m    532\u001b[0m                 prompts,\n\u001b[0;32m    533\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    534\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    535\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    536\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    537\u001b[0m             )\n\u001b[0;32m    538\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    539\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    540\u001b[0m         )\n\u001b[0;32m    541\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    542\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\llms\\huggingface_pipeline.py:202\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m batch_prompts \u001b[39m=\u001b[39m prompts[i : i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]\n\u001b[0;32m    201\u001b[0m \u001b[39m# Process batch of prompts\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m responses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline(batch_prompts)\n\u001b[0;32m    204\u001b[0m \u001b[39m# Process each response in the batch\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m j, response \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(responses):\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:208\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, text_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    168\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(text_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1121\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1117\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1118\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   1119\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1120\u001b[0m     )\n\u001b[1;32m-> 1121\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(final_iterator)\n\u001b[0;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m   1123\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[39m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1045\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1046\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[0;32m   1047\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:271\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m         generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m prefix_length\n\u001b[0;32m    270\u001b[0m \u001b[39m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m generated_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[0;32m    272\u001b[0m out_b \u001b[39m=\u001b[39m generated_sequence\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1719\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1712\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1713\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1714\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1715\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1716\u001b[0m     )\n\u001b[0;32m   1718\u001b[0m     \u001b[39m# 13. run sample\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(\n\u001b[0;32m   1720\u001b[0m         input_ids,\n\u001b[0;32m   1721\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   1722\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[0;32m   1723\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   1724\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[0;32m   1725\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[0;32m   1726\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[0;32m   1727\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   1728\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   1729\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[0;32m   1730\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   1731\u001b[0m     )\n\u001b[0;32m   1733\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SEARCH:\n\u001b[0;32m   1734\u001b[0m     \u001b[39m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m     beam_scorer \u001b[39m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1736\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1737\u001b[0m         num_beams\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1742\u001b[0m         max_length\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mmax_length,\n\u001b[0;32m   1743\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alanj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:2837\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[39m# sample\u001b[39;00m\n\u001b[0;32m   2836\u001b[0m probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(next_token_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m-> 2837\u001b[0m next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(probs, num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m   2839\u001b[0m \u001b[39m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[0;32m   2840\u001b[0m \u001b[39mif\u001b[39;00m eos_token_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    print(dialogue_chain.run({\n",
    "        \"about\": \"James likes paw patrol.\",\n",
    "        \"task\" : task\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c97bd56f4a456e81622cc4cf3afd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StableLMEpochForCausalLM(\n",
       "  (model): StableLMEpochModel(\n",
       "    (embed_tokens): Embedding(50304, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (self_attn): Attention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (o_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (gate_proj): Linear(in_features=2560, out_features=6912, bias=False)\n",
       "          (up_proj): Linear(in_features=2560, out_features=6912, bias=False)\n",
       "          (down_proj): Linear(in_features=6912, out_features=2560, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"stabilityai/stablelm-3b-4e1t\",\n",
    "  trust_remote_code=True,\n",
    "  torch_dtype=\"auto\",\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "James is learning how to get ready for school, chase from paw patrol helps\n",
      "\n",
      "\n",
      "\n",
      "James is learning how to get ready for school, chase from paw patrol helps\n",
      "\n",
      "Please Subscribe: https://www.youtube.com/channel/UCwZWnqb1V0K-6Fyw1L4fQg\n",
      "\n",
      "James is learning how to get ready for school, chase from paw patrol helps\n",
      "\n",
      "James is learning how to get ready for school, chase from paw patrol helps\n",
      "\n",
      "James is learning how to get ready for school,\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"\"\"\n",
    "James is learning how to get ready for school, chase from paw patrol helps\n",
    "\n",
    "\n",
    "\"\"\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "tokens = model.generate(\n",
    "  **inputs,\n",
    "  max_new_tokens=100,\n",
    "  temperature=0.75,\n",
    "  top_p=0.95,\n",
    "  do_sample=True,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(tokens[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
